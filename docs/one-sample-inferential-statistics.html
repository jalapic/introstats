<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 One Sample Inferential Statistics | PSY317L &amp; PSY120R Textbook</title>
  <meta name="description" content="Chapter 10 One Sample Inferential Statistics | PSY317L &amp; PSY120R Textbook" />
  <meta name="generator" content="bookdown 0.23 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 One Sample Inferential Statistics | PSY317L &amp; PSY120R Textbook" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 One Sample Inferential Statistics | PSY317L &amp; PSY120R Textbook" />
  
  
  

<meta name="author" content="James P. Curley &amp; Tyler M. Milewski" />


<meta name="date" content="2021-09-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="hypothesis-testing.html"/>
<link rel="next" href="two-sample-inferential-statistics.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intro to Statistics & R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome to PSY317 / PSY120R !</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#what-this-book-includes-and-what-it-doesnt"><i class="fa fa-check"></i><b>1.1</b> What this book includes and what it doesn’t</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#how-to-use-this-guide"><i class="fa fa-check"></i><b>1.2</b> How to use this guide</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.3</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#references"><i class="fa fa-check"></i><b>1.4</b> References</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#other-places-to-find-help-about-r-and-statistics"><i class="fa fa-check"></i><b>1.5</b> Other places to find help about R and Statistics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#downloading-r"><i class="fa fa-check"></i><b>2.1</b> Downloading R</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#downloading-rstudio"><i class="fa fa-check"></i><b>2.2</b> Downloading RStudio</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#successful-installation"><i class="fa fa-check"></i><b>2.2.1</b> Successful installation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#using-rcloud"><i class="fa fa-check"></i><b>2.3</b> Using RCloud</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#the-rstudio-environment"><i class="fa fa-check"></i><b>2.4</b> The RStudio Environment</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#running-code"><i class="fa fa-check"></i><b>2.5</b> Running Code</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#the-console"><i class="fa fa-check"></i><b>2.5.1</b> The Console</a></li>
<li class="chapter" data-level="2.5.2" data-path="introduction.html"><a href="introduction.html#rscript"><i class="fa fa-check"></i><b>2.5.2</b> RScript</a></li>
<li class="chapter" data-level="2.5.3" data-path="introduction.html"><a href="introduction.html#saving-an-rscript"><i class="fa fa-check"></i><b>2.5.3</b> Saving an RScript</a></li>
<li class="chapter" data-level="2.5.4" data-path="introduction.html"><a href="introduction.html#open-an-existing-rscript"><i class="fa fa-check"></i><b>2.5.4</b> Open an existing RScript</a></li>
<li class="chapter" data-level="2.5.5" data-path="introduction.html"><a href="introduction.html#running-code-in-scripts"><i class="fa fa-check"></i><b>2.5.5</b> Running Code in Scripts</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#packages"><i class="fa fa-check"></i><b>2.6</b> Packages</a></li>
<li class="chapter" data-level="2.7" data-path="introduction.html"><a href="introduction.html#working-with-rstudio-in-psy317l"><i class="fa fa-check"></i><b>2.7</b> Working with RStudio in PSY317L</a></li>
<li class="chapter" data-level="2.8" data-path="introduction.html"><a href="introduction.html#quitting-rstudio"><i class="fa fa-check"></i><b>2.8</b> Quitting RStudio</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basic-syntax.html"><a href="basic-syntax.html"><i class="fa fa-check"></i><b>3</b> Basic Syntax</a>
<ul>
<li class="chapter" data-level="3.1" data-path="basic-syntax.html"><a href="basic-syntax.html#simple-mathematical-syntax"><i class="fa fa-check"></i><b>3.1</b> Simple mathematical syntax</a></li>
<li class="chapter" data-level="3.2" data-path="basic-syntax.html"><a href="basic-syntax.html#assignment"><i class="fa fa-check"></i><b>3.2</b> Assignment</a></li>
<li class="chapter" data-level="3.3" data-path="basic-syntax.html"><a href="basic-syntax.html#vectors"><i class="fa fa-check"></i><b>3.3</b> Vectors</a></li>
<li class="chapter" data-level="3.4" data-path="basic-syntax.html"><a href="basic-syntax.html#characters"><i class="fa fa-check"></i><b>3.4</b> Characters</a></li>
<li class="chapter" data-level="3.5" data-path="basic-syntax.html"><a href="basic-syntax.html#naming-of-objects"><i class="fa fa-check"></i><b>3.5</b> Naming of objects</a></li>
<li class="chapter" data-level="3.6" data-path="basic-syntax.html"><a href="basic-syntax.html#logical-operators"><i class="fa fa-check"></i><b>3.6</b> Logical Operators</a></li>
<li class="chapter" data-level="3.7" data-path="basic-syntax.html"><a href="basic-syntax.html#some-things-that-are-useful-to-know."><i class="fa fa-check"></i><b>3.7</b> Some things that are useful to know.</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="basic-syntax.html"><a href="basic-syntax.html#tab-is-your-friend"><i class="fa fa-check"></i><b>3.7.1</b> Tab is your friend</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="basic-syntax.html"><a href="basic-syntax.html#error-messages"><i class="fa fa-check"></i><b>3.8</b> Error Messages</a></li>
<li class="chapter" data-level="3.9" data-path="basic-syntax.html"><a href="basic-syntax.html#functions"><i class="fa fa-check"></i><b>3.9</b> Functions</a></li>
<li class="chapter" data-level="3.10" data-path="basic-syntax.html"><a href="basic-syntax.html#chaining-syntax"><i class="fa fa-check"></i><b>3.10</b> Chaining Syntax</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html"><i class="fa fa-check"></i><b>4</b> Introduction to Data Carpentry</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#data-types"><i class="fa fa-check"></i><b>4.1</b> Data Types</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#categorical-data"><i class="fa fa-check"></i><b>4.1.1</b> Categorical Data</a></li>
<li class="chapter" data-level="4.1.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#numerical-data-discrete-vs.-continuous"><i class="fa fa-check"></i><b>4.1.2</b> Numerical Data (Discrete vs. Continuous)</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#importing-data"><i class="fa fa-check"></i><b>4.2</b> Importing Data</a></li>
<li class="chapter" data-level="4.3" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#introduction-to-dataframes"><i class="fa fa-check"></i><b>4.3</b> Introduction to Dataframes</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#dataframe-basics"><i class="fa fa-check"></i><b>4.3.1</b> Dataframe basics</a></li>
<li class="chapter" data-level="4.3.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#indexing-dataframes."><i class="fa fa-check"></i><b>4.3.2</b> Indexing dataframes.</a></li>
<li class="chapter" data-level="4.3.3" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#adding-and-removing-columns"><i class="fa fa-check"></i><b>4.3.3</b> Adding and removing columns</a></li>
<li class="chapter" data-level="4.3.4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#structure-of-datasets"><i class="fa fa-check"></i><b>4.3.4</b> Structure of Datasets</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#manually-creating-a-dataframe"><i class="fa fa-check"></i><b>4.4</b> Manually creating a Dataframe</a></li>
<li class="chapter" data-level="4.5" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#tidyverse"><i class="fa fa-check"></i><b>4.5</b> tidyverse</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#table"><i class="fa fa-check"></i><b>4.5.1</b> table()</a></li>
<li class="chapter" data-level="4.5.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#filter---subsetting-data"><i class="fa fa-check"></i><b>4.5.2</b> filter() - Subsetting Data</a></li>
<li class="chapter" data-level="4.5.3" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#select---selecting-specific-columns"><i class="fa fa-check"></i><b>4.5.3</b> select() - Selecting specific columns</a></li>
<li class="chapter" data-level="4.5.4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#mutate---creating-new-columns"><i class="fa fa-check"></i><b>4.5.4</b> mutate() - Creating new columns</a></li>
<li class="chapter" data-level="4.5.5" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#arrange---sort-data-columns"><i class="fa fa-check"></i><b>4.5.5</b> arrange() - Sort Data Columns</a></li>
<li class="chapter" data-level="4.5.6" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#chaining-together"><i class="fa fa-check"></i><b>4.5.6</b> Chaining together</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#wide-versus-long-data"><i class="fa fa-check"></i><b>4.6</b> Wide versus Long Data</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#wide-to-long"><i class="fa fa-check"></i><b>4.6.1</b> Wide to Long</a></li>
<li class="chapter" data-level="4.6.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#long-to-wide"><i class="fa fa-check"></i><b>4.6.2</b> Long to Wide</a></li>
<li class="chapter" data-level="4.6.3" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#real-data-example."><i class="fa fa-check"></i><b>4.6.3</b> Real Data Example.</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#joins"><i class="fa fa-check"></i><b>4.7</b> Joins</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>5</b> Data Visualization</a>
<ul>
<li class="chapter" data-level="5.1" data-path="data-visualization.html"><a href="data-visualization.html#introduction-to-ggplot2"><i class="fa fa-check"></i><b>5.1</b> Introduction to ggplot2</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="data-visualization.html"><a href="data-visualization.html#assigning-plots"><i class="fa fa-check"></i><b>5.1.1</b> Assigning plots</a></li>
<li class="chapter" data-level="5.1.2" data-path="data-visualization.html"><a href="data-visualization.html#titles-and-axes-titles"><i class="fa fa-check"></i><b>5.1.2</b> Titles and Axes Titles</a></li>
<li class="chapter" data-level="5.1.3" data-path="data-visualization.html"><a href="data-visualization.html#colors-shapes-and-sizes"><i class="fa fa-check"></i><b>5.1.3</b> Colors, Shapes and Sizes</a></li>
<li class="chapter" data-level="5.1.4" data-path="data-visualization.html"><a href="data-visualization.html#themes"><i class="fa fa-check"></i><b>5.1.4</b> Themes</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-visualization.html"><a href="data-visualization.html#histograms"><i class="fa fa-check"></i><b>5.2</b> Histograms</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="data-visualization.html"><a href="data-visualization.html#histograms-with-ggplot2"><i class="fa fa-check"></i><b>5.2.1</b> Histograms with ggplot2</a></li>
<li class="chapter" data-level="5.2.2" data-path="data-visualization.html"><a href="data-visualization.html#density-curves"><i class="fa fa-check"></i><b>5.2.2</b> Density Curves</a></li>
<li class="chapter" data-level="5.2.3" data-path="data-visualization.html"><a href="data-visualization.html#comparing-distributions"><i class="fa fa-check"></i><b>5.2.3</b> Comparing Distributions</a></li>
<li class="chapter" data-level="5.2.4" data-path="data-visualization.html"><a href="data-visualization.html#stem-and-leaf-plots"><i class="fa fa-check"></i><b>5.2.4</b> Stem-and-Leaf Plots</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="data-visualization.html"><a href="data-visualization.html#scatterplots"><i class="fa fa-check"></i><b>5.3</b> Scatterplots</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="data-visualization.html"><a href="data-visualization.html#bubble-charts"><i class="fa fa-check"></i><b>5.3.1</b> Bubble Charts</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="data-visualization.html"><a href="data-visualization.html#line-graphs"><i class="fa fa-check"></i><b>5.4</b> Line Graphs</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="data-visualization.html"><a href="data-visualization.html#multiple-line-graphs"><i class="fa fa-check"></i><b>5.4.1</b> Multiple Line Graphs</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="data-visualization.html"><a href="data-visualization.html#comparing-distributions-across-groups"><i class="fa fa-check"></i><b>5.5</b> Comparing Distributions across Groups</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="data-visualization.html"><a href="data-visualization.html#strip-plots"><i class="fa fa-check"></i><b>5.5.1</b> Strip Plots</a></li>
<li class="chapter" data-level="5.5.2" data-path="data-visualization.html"><a href="data-visualization.html#boxplots"><i class="fa fa-check"></i><b>5.5.2</b> Boxplots</a></li>
<li class="chapter" data-level="5.5.3" data-path="data-visualization.html"><a href="data-visualization.html#violin-plots"><i class="fa fa-check"></i><b>5.5.3</b> Violin Plots</a></li>
<li class="chapter" data-level="5.5.4" data-path="data-visualization.html"><a href="data-visualization.html#stacked-boxplots"><i class="fa fa-check"></i><b>5.5.4</b> Stacked Boxplots</a></li>
<li class="chapter" data-level="5.5.5" data-path="data-visualization.html"><a href="data-visualization.html#ridgeline-plots"><i class="fa fa-check"></i><b>5.5.5</b> Ridgeline Plots</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="data-visualization.html"><a href="data-visualization.html#bar-graphs"><i class="fa fa-check"></i><b>5.6</b> Bar Graphs</a></li>
<li class="chapter" data-level="5.7" data-path="data-visualization.html"><a href="data-visualization.html#small-multiples"><i class="fa fa-check"></i><b>5.7</b> Small Multiples</a></li>
<li class="chapter" data-level="5.8" data-path="data-visualization.html"><a href="data-visualization.html#saving-and-exporting-ggplot2-graphs"><i class="fa fa-check"></i><b>5.8</b> Saving and Exporting ggplot2 graphs</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>6</b> Descriptives</a>
<ul>
<li class="chapter" data-level="6.1" data-path="descriptives.html"><a href="descriptives.html#sample-vs-population"><i class="fa fa-check"></i><b>6.1</b> Sample vs Population</a></li>
<li class="chapter" data-level="6.2" data-path="descriptives.html"><a href="descriptives.html#sample-and-population-size"><i class="fa fa-check"></i><b>6.2</b> Sample and Population Size</a></li>
<li class="chapter" data-level="6.3" data-path="descriptives.html"><a href="descriptives.html#central-tendency"><i class="fa fa-check"></i><b>6.3</b> Central Tendency</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="descriptives.html"><a href="descriptives.html#mode"><i class="fa fa-check"></i><b>6.3.1</b> Mode</a></li>
<li class="chapter" data-level="6.3.2" data-path="descriptives.html"><a href="descriptives.html#median"><i class="fa fa-check"></i><b>6.3.2</b> Median</a></li>
<li class="chapter" data-level="6.3.3" data-path="descriptives.html"><a href="descriptives.html#mean"><i class="fa fa-check"></i><b>6.3.3</b> Mean</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="descriptives.html"><a href="descriptives.html#variation"><i class="fa fa-check"></i><b>6.4</b> Variation</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="descriptives.html"><a href="descriptives.html#range"><i class="fa fa-check"></i><b>6.4.1</b> Range</a></li>
<li class="chapter" data-level="6.4.2" data-path="descriptives.html"><a href="descriptives.html#interquartile-range"><i class="fa fa-check"></i><b>6.4.2</b> Interquartile Range</a></li>
<li class="chapter" data-level="6.4.3" data-path="descriptives.html"><a href="descriptives.html#average-deviation"><i class="fa fa-check"></i><b>6.4.3</b> Average Deviation</a></li>
<li class="chapter" data-level="6.4.4" data-path="descriptives.html"><a href="descriptives.html#standard-deviation"><i class="fa fa-check"></i><b>6.4.4</b> Standard Deviation</a></li>
<li class="chapter" data-level="6.4.5" data-path="descriptives.html"><a href="descriptives.html#variance"><i class="fa fa-check"></i><b>6.4.5</b> Variance</a></li>
<li class="chapter" data-level="6.4.6" data-path="descriptives.html"><a href="descriptives.html#average-versus-standard-deviation"><i class="fa fa-check"></i><b>6.4.6</b> Average versus Standard Deviation</a></li>
<li class="chapter" data-level="6.4.7" data-path="descriptives.html"><a href="descriptives.html#sample-standard-deviation"><i class="fa fa-check"></i><b>6.4.7</b> Sample Standard Deviation</a></li>
<li class="chapter" data-level="6.4.8" data-path="descriptives.html"><a href="descriptives.html#sample-versus-population-standard-deviation"><i class="fa fa-check"></i><b>6.4.8</b> Sample versus Population Standard Deviation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="descriptives.html"><a href="descriptives.html#descriptive-statistics-in-r"><i class="fa fa-check"></i><b>6.5</b> Descriptive Statistics in R</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="descriptives.html"><a href="descriptives.html#dealing-with-missing-data"><i class="fa fa-check"></i><b>6.5.1</b> Dealing with Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="descriptives.html"><a href="descriptives.html#descriptives-for-datasets"><i class="fa fa-check"></i><b>6.6</b> Descriptives for Datasets</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="descriptives.html"><a href="descriptives.html#descriptives-for-groups"><i class="fa fa-check"></i><b>6.6.1</b> Descriptives for Groups</a></li>
<li class="chapter" data-level="6.6.2" data-path="descriptives.html"><a href="descriptives.html#counts-by-group"><i class="fa fa-check"></i><b>6.6.2</b> Counts by Group</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>7</b> Distributions</a>
<ul>
<li class="chapter" data-level="7.0.1" data-path="distributions.html"><a href="distributions.html#uniform-distribution"><i class="fa fa-check"></i><b>7.0.1</b> Uniform Distribution</a></li>
<li class="chapter" data-level="7.0.2" data-path="distributions.html"><a href="distributions.html#bimodal-distribution"><i class="fa fa-check"></i><b>7.0.2</b> Bimodal Distribution</a></li>
<li class="chapter" data-level="7.0.3" data-path="distributions.html"><a href="distributions.html#normal-distribution"><i class="fa fa-check"></i><b>7.0.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="7.0.4" data-path="distributions.html"><a href="distributions.html#standard-normal-distribution"><i class="fa fa-check"></i><b>7.0.4</b> Standard Normal Distribution</a></li>
<li class="chapter" data-level="7.0.5" data-path="distributions.html"><a href="distributions.html#skewness-and-kurtosis"><i class="fa fa-check"></i><b>7.0.5</b> Skewness and Kurtosis</a></li>
<li class="chapter" data-level="7.1" data-path="distributions.html"><a href="distributions.html#z-scores"><i class="fa fa-check"></i><b>7.1</b> Z-scores</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="distributions.html"><a href="distributions.html#z-scores-in-samples."><i class="fa fa-check"></i><b>7.1.1</b> z-scores in samples.</a></li>
<li class="chapter" data-level="7.1.2" data-path="distributions.html"><a href="distributions.html#using-z-scores-to-determine-probabilities"><i class="fa fa-check"></i><b>7.1.2</b> Using z-scores to determine probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="distributions.html"><a href="distributions.html#what-is-a-sampling-distribution"><i class="fa fa-check"></i><b>7.2</b> What is a Sampling Distribution ?</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="distributions.html"><a href="distributions.html#sample-size-and-the-sampling-distribution"><i class="fa fa-check"></i><b>7.2.1</b> Sample Size and the Sampling Distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="distributions.html"><a href="distributions.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.3</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="7.4" data-path="distributions.html"><a href="distributions.html#sampling-distribution-problems"><i class="fa fa-check"></i><b>7.4</b> Sampling distribution problems</a></li>
<li class="chapter" data-level="7.5" data-path="distributions.html"><a href="distributions.html#the-t-distribution"><i class="fa fa-check"></i><b>7.5</b> The t-distribution</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>8</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="8.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#sample-means-as-estimates."><i class="fa fa-check"></i><b>8.1</b> Sample means as estimates.</a></li>
<li class="chapter" data-level="8.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#calculating-a-confidence-interval-with-z-distribution"><i class="fa fa-check"></i><b>8.2</b> Calculating a confidence interval with z-distribution</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#other-confidence-intervals-ranges"><i class="fa fa-check"></i><b>8.2.1</b> Other Confidence Intervals ranges</a></li>
<li class="chapter" data-level="8.2.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#confidence-intervals-and-sample-size"><i class="fa fa-check"></i><b>8.2.2</b> Confidence Intervals and Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#confidence-intervals-with-t-distribution"><i class="fa fa-check"></i><b>8.3</b> Confidence Intervals with t-distribution</a></li>
<li class="chapter" data-level="8.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#calculating-a-t-distribution-confidence-interval"><i class="fa fa-check"></i><b>8.4</b> Calculating a t-distribution Confidence Interval</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#t-distribution-cis-and-sample-size."><i class="fa fa-check"></i><b>8.4.1</b> t-distribution CIs and sample size.</a></li>
<li class="chapter" data-level="8.4.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#other-confidence-intervals-ranges-for-t-distribution"><i class="fa fa-check"></i><b>8.4.2</b> Other Confidence Intervals ranges for t-distribution</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#comparing-cis-using-the-z--and-t-distributions"><i class="fa fa-check"></i><b>8.5</b> Comparing CIs using the z- and t-distributions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>9</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="9.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-tailed-and-one-tailed-tests"><i class="fa fa-check"></i><b>9.1</b> Two-tailed and One-tailed tests</a></li>
<li class="chapter" data-level="9.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#examples-of-1--and-2-tailed-tests"><i class="fa fa-check"></i><b>9.2</b> Examples of 1- and 2-tailed tests</a></li>
<li class="chapter" data-level="9.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#significance-levels-and-p-values"><i class="fa fa-check"></i><b>9.3</b> Significance Levels and p-values</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html"><i class="fa fa-check"></i><b>10</b> One Sample Inferential Statistics</a>
<ul>
<li class="chapter" data-level="10.1" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#one-sample-z-tests"><i class="fa fa-check"></i><b>10.1</b> One-sample z-tests</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#sampling-distribution-recap"><i class="fa fa-check"></i><b>10.1.1</b> Sampling Distribution Recap</a></li>
<li class="chapter" data-level="10.1.2" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#calculating-p-values-for-z-test"><i class="fa fa-check"></i><b>10.1.2</b> Calculating p-values for z-test</a></li>
<li class="chapter" data-level="10.1.3" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#using-critical-values"><i class="fa fa-check"></i><b>10.1.3</b> Using critical values</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#one-sample-t-tests"><i class="fa fa-check"></i><b>10.2</b> One-sample t-tests</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#critical-values-for-the-one-sample-t-test"><i class="fa fa-check"></i><b>10.2.1</b> Critical values for the one-sample t-test</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#conducting-one-sample-t-tests-in-r"><i class="fa fa-check"></i><b>10.3</b> Conducting one-sample t-tests in R</a></li>
<li class="chapter" data-level="10.4" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#assumptions-of-the-one-sample-t-test"><i class="fa fa-check"></i><b>10.4</b> Assumptions of the one-sample t-test</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html"><i class="fa fa-check"></i><b>11</b> Two Sample Inferential Statistics</a>
<ul>
<li class="chapter" data-level="11.1" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#independent-samples-t-test"><i class="fa fa-check"></i><b>11.1</b> Independent Samples t-test</a></li>
<li class="chapter" data-level="11.2" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#sampling-distribution-of-the-difference-in-sample-means"><i class="fa fa-check"></i><b>11.2</b> Sampling Distribution of the Difference in Sample Means</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#visualizing-the-sampling-distribution"><i class="fa fa-check"></i><b>11.2.1</b> Visualizing the Sampling Distribution</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#pooled-standard-deviation"><i class="fa fa-check"></i><b>11.3</b> Pooled Standard Deviation</a></li>
<li class="chapter" data-level="11.4" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#theory-behind-students-t-test"><i class="fa fa-check"></i><b>11.4</b> Theory behind Student’s t-test</a></li>
<li class="chapter" data-level="11.5" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#confidence-interval-for-difference-in-means"><i class="fa fa-check"></i><b>11.5</b> Confidence Interval for Difference in Means</a></li>
<li class="chapter" data-level="11.6" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#conducting-the-student-t-test-in-r"><i class="fa fa-check"></i><b>11.6</b> Conducting the Student t-test in R</a></li>
<li class="chapter" data-level="11.7" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#assumptions-of-the-independent-t-test"><i class="fa fa-check"></i><b>11.7</b> Assumptions of the Independent t-test</a></li>
<li class="chapter" data-level="11.8" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#welchs-t-test"><i class="fa fa-check"></i><b>11.8</b> Welch’s t-test</a></li>
<li class="chapter" data-level="11.9" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#effect-size-for-independent-two-sample-t-tests"><i class="fa fa-check"></i><b>11.9</b> Effect Size for Independent two sample t-tests:</a></li>
<li class="chapter" data-level="11.10" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#paired-t-tests"><i class="fa fa-check"></i><b>11.10</b> Paired t-tests</a>
<ul>
<li class="chapter" data-level="11.10.1" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#the-paired-t-test-is-a-one-sample-t-test"><i class="fa fa-check"></i><b>11.10.1</b> The paired t-test is a one-sample t-test</a></li>
<li class="chapter" data-level="11.10.2" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#one-tailed-paired-t-tests"><i class="fa fa-check"></i><b>11.10.2</b> One-tailed paired t-tests</a></li>
<li class="chapter" data-level="11.10.3" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#calculating-effect-sizes"><i class="fa fa-check"></i><b>11.10.3</b> Calculating effect sizes</a></li>
</ul></li>
<li class="chapter" data-level="11.11" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#non-parametric-alternatives-for-independent-t-tests"><i class="fa fa-check"></i><b>11.11</b> Non-parametric Alternatives for Independent t-tests</a></li>
<li class="chapter" data-level="11.12" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#non-parametric-alternatives-to-the-two-sample-t-tests"><i class="fa fa-check"></i><b>11.12</b> Non-parametric Alternatives to the Two Sample t-tests</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>12</b> Correlation</a>
<ul>
<li class="chapter" data-level="12.1" data-path="correlation.html"><a href="correlation.html#pearson-correlation"><i class="fa fa-check"></i><b>12.1</b> Pearson Correlation</a></li>
<li class="chapter" data-level="12.2" data-path="correlation.html"><a href="correlation.html#cross-products"><i class="fa fa-check"></i><b>12.2</b> Cross-products</a></li>
<li class="chapter" data-level="12.3" data-path="correlation.html"><a href="correlation.html#conducting-a-pearson-correlation-test"><i class="fa fa-check"></i><b>12.3</b> Conducting a Pearson Correlation Test</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="correlation.html"><a href="correlation.html#significance-testing-a-pearson-correlation"><i class="fa fa-check"></i><b>12.3.1</b> Significance Testing a Pearson Correlation</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="correlation.html"><a href="correlation.html#assumptions-of-pearsons-correlation"><i class="fa fa-check"></i><b>12.4</b> Assumptions of Pearson’s Correlation</a></li>
<li class="chapter" data-level="12.5" data-path="correlation.html"><a href="correlation.html#confidence-intervals-for-r"><i class="fa fa-check"></i><b>12.5</b> Confidence Intervals for r</a></li>
<li class="chapter" data-level="12.6" data-path="correlation.html"><a href="correlation.html#partial-correlations"><i class="fa fa-check"></i><b>12.6</b> Partial Correlations</a></li>
<li class="chapter" data-level="12.7" data-path="correlation.html"><a href="correlation.html#non-parametric-correlations"><i class="fa fa-check"></i><b>12.7</b> Non-parametric Correlations</a></li>
<li class="chapter" data-level="12.8" data-path="correlation.html"><a href="correlation.html#point-biserial-correlation"><i class="fa fa-check"></i><b>12.8</b> Point-Biserial Correlation</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>13</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="13.1" data-path="linear-regression.html"><a href="linear-regression.html#introduction-to-linear-regression"><i class="fa fa-check"></i><b>13.1</b> Introduction to Linear Regression</a></li>
<li class="chapter" data-level="13.2" data-path="linear-regression.html"><a href="linear-regression.html#a-and-b"><i class="fa fa-check"></i><b>13.2</b> a and b</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="linear-regression.html"><a href="linear-regression.html#how-to-calculate-a-and-b-in-r"><i class="fa fa-check"></i><b>13.2.1</b> How to calculate a and b in R</a></li>
<li class="chapter" data-level="13.2.2" data-path="linear-regression.html"><a href="linear-regression.html#how-to-calculate-a-and-b-by-hand"><i class="fa fa-check"></i><b>13.2.2</b> How to calculate a and b ‘by hand’</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="linear-regression.html"><a href="linear-regression.html#residuals"><i class="fa fa-check"></i><b>13.3</b> Residuals</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="linear-regression.html"><a href="linear-regression.html#how-to-calculate-the-residuals"><i class="fa fa-check"></i><b>13.3.1</b> How to calculate the residuals</a></li>
<li class="chapter" data-level="13.3.2" data-path="linear-regression.html"><a href="linear-regression.html#visualizing-the-residuals"><i class="fa fa-check"></i><b>13.3.2</b> Visualizing the Residuals</a></li>
<li class="chapter" data-level="13.3.3" data-path="linear-regression.html"><a href="linear-regression.html#comparing-our-trendline-to-other-trendlines"><i class="fa fa-check"></i><b>13.3.3</b> Comparing our trendline to other trendlines</a></li>
<li class="chapter" data-level="13.3.4" data-path="linear-regression.html"><a href="linear-regression.html#coefficient-of-determination-r2"><i class="fa fa-check"></i><b>13.3.4</b> Coefficient of Determination R2</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="linear-regression.html"><a href="linear-regression.html#standard-error-of-the-estimate"><i class="fa fa-check"></i><b>13.4</b> Standard Error of the Estimate</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="linear-regression.html"><a href="linear-regression.html#what-to-do-with-the-standard-error-of-the-estimate"><i class="fa fa-check"></i><b>13.4.1</b> What to do with the Standard Error of the Estimate ?</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="linear-regression.html"><a href="linear-regression.html#goodness-of-fit-test---f-ratio"><i class="fa fa-check"></i><b>13.5</b> Goodness of Fit Test - F-ratio</a></li>
<li class="chapter" data-level="13.6" data-path="linear-regression.html"><a href="linear-regression.html#assumptions-of-linear-regression"><i class="fa fa-check"></i><b>13.6</b> Assumptions of Linear Regression</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="linear-regression.html"><a href="linear-regression.html#normality-of-residuals"><i class="fa fa-check"></i><b>13.6.1</b> Normality of Residuals</a></li>
<li class="chapter" data-level="13.6.2" data-path="linear-regression.html"><a href="linear-regression.html#linearity"><i class="fa fa-check"></i><b>13.6.2</b> 2. Linearity —</a></li>
<li class="chapter" data-level="13.6.3" data-path="linear-regression.html"><a href="linear-regression.html#homogeneity-of-variance-homoscedasticity"><i class="fa fa-check"></i><b>13.6.3</b> 3. Homogeneity of Variance / Homoscedasticity</a></li>
<li class="chapter" data-level="13.6.4" data-path="linear-regression.html"><a href="linear-regression.html#no-colinearity"><i class="fa fa-check"></i><b>13.6.4</b> No Colinearity</a></li>
<li class="chapter" data-level="13.6.5" data-path="linear-regression.html"><a href="linear-regression.html#unusual-datapoints"><i class="fa fa-check"></i><b>13.6.5</b> Unusual Datapoints</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="linear-regression.html"><a href="linear-regression.html#examining-individual-predictor-estimates"><i class="fa fa-check"></i><b>13.7</b> Examining individual predictor estimates</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="linear-regression.html"><a href="linear-regression.html#confidence-interval-of-b."><i class="fa fa-check"></i><b>13.7.1</b> 95% confidence interval of ‘b’.</a></li>
<li class="chapter" data-level="13.7.2" data-path="linear-regression.html"><a href="linear-regression.html#standard-error-of-b"><i class="fa fa-check"></i><b>13.7.2</b> Standard Error of b</a></li>
<li class="chapter" data-level="13.7.3" data-path="linear-regression.html"><a href="linear-regression.html#calculating-95-confidence-interval-of-b-by-hand"><i class="fa fa-check"></i><b>13.7.3</b> Calculating 95% confidence interval of ‘b’ by hand</a></li>
<li class="chapter" data-level="13.7.4" data-path="linear-regression.html"><a href="linear-regression.html#signifcance-testing-b"><i class="fa fa-check"></i><b>13.7.4</b> Signifcance Testing b</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="permutation-testing.html"><a href="permutation-testing.html"><i class="fa fa-check"></i><b>14</b> Permutation Testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="permutation-testing.html"><a href="permutation-testing.html#t-test-permutation"><i class="fa fa-check"></i><b>14.1</b> t-test Permutation</a></li>
<li class="chapter" data-level="14.2" data-path="permutation-testing.html"><a href="permutation-testing.html#correlation-coefficient-permutation-tests"><i class="fa fa-check"></i><b>14.2</b> Correlation Coefficient Permutation Tests</a></li>
<li class="chapter" data-level="14.3" data-path="permutation-testing.html"><a href="permutation-testing.html#permutation-test-for-a-paired-t-test"><i class="fa fa-check"></i><b>14.3</b> Permutation test for a Paired t-test</a></li>
<li class="chapter" data-level="14.4" data-path="permutation-testing.html"><a href="permutation-testing.html#permutation-tests-in-packages"><i class="fa fa-check"></i><b>14.4</b> Permutation tests in Packages</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="analyzing-categorical-data.html"><a href="analyzing-categorical-data.html"><i class="fa fa-check"></i><b>15</b> Analyzing Categorical Data</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PSY317L &amp; PSY120R Textbook</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="one-sample-inferential-statistics" class="section level1" number="10">
<h1><span class="header-section-number">Chapter 10</span> One Sample Inferential Statistics</h1>
<p>The general question at hand with one-sample inferential tests, is that we wish to test the probability that our one sample of data comes from a population that has a true population mean <span class="math inline">\(\mu\)</span> that is equal to, greater than, or less than, some specific value. We will look at two ways of doing this - firstly using a z-test and then using t-tests.</p>
<p><br><br></p>
<div id="one-sample-z-tests" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> One-sample z-tests</h2>
<div id="sampling-distribution-recap" class="section level3" number="10.1.1">
<h3><span class="header-section-number">10.1.1</span> Sampling Distribution Recap</h3>
<p>In one-sample z-tests we are provided with the population mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. We then collect or are given one sample of data of size <span class="math inline">\(n\)</span>. From this sample, we calculate the sample mean <span class="math inline">\(\overline{x}\)</span>. The question then becomes, how likely were we to get a sample mean as large or as small as the sample that we got?</p>
<p>To answer this, we need to think in terms of the sampling distribution of sample means. We need to recognize that our one observed sample mean <span class="math inline">\(\overline{x}\)</span> is just one sample mean that we could have got from a sampling distribution of sample means.</p>
<p>For instance, look at the population below. This is a normally distributed population of IQ scores, with a population mean <span class="math inline">\(\mu = 100\)</span> and a population standard deviation <span class="math inline">\(\sigma = 15\)</span>.</p>
<p><img src="img/zt1.png" /></p>
<p>Let’s take a sample of size <span class="math inline">\(n=25\)</span> from this population, round the individual scores to 1dp, and get the mean of the sample:</p>
<div class="sourceCode" id="cb999"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb999-1"><a href="one-sample-inferential-statistics.html#cb999-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb999-2"><a href="one-sample-inferential-statistics.html#cb999-2" aria-hidden="true" tabindex="-1"></a>samp1 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="at">n=</span><span class="dv">25</span>, <span class="at">mean=</span><span class="dv">100</span>, <span class="at">sd=</span><span class="dv">15</span>),<span class="dv">1</span>)</span>
<span id="cb999-3"><a href="one-sample-inferential-statistics.html#cb999-3" aria-hidden="true" tabindex="-1"></a>samp1</span></code></pre></div>
<pre><code>##  [1]  90.6 102.8  87.5 123.9 104.9  87.7 107.3 111.1 108.6  95.4 122.7 105.8  90.7  66.8 116.9
## [16]  99.3  99.8 114.2 112.3 108.9 113.8 111.7 101.1  70.2 109.3</code></pre>
<div class="sourceCode" id="cb1001"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1001-1"><a href="one-sample-inferential-statistics.html#cb1001-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(samp1)</span></code></pre></div>
<pre><code>## [1] 102.532</code></pre>
<p>Our one observed sample has a sample mean of <span class="math inline">\(\overline{x}=102.5\)</span></p>
<p>If we repeated this step and got a second sample of <span class="math inline">\(n=25\)</span>, we could get another sample mean <span class="math inline">\(\overline{x}\)</span>:</p>
<div class="sourceCode" id="cb1003"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1003-1"><a href="one-sample-inferential-statistics.html#cb1003-1" aria-hidden="true" tabindex="-1"></a>samp2 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="at">n=</span><span class="dv">25</span>, <span class="at">mean=</span><span class="dv">100</span>, <span class="at">sd=</span><span class="dv">15</span>),<span class="dv">1</span>)</span>
<span id="cb1003-2"><a href="one-sample-inferential-statistics.html#cb1003-2" aria-hidden="true" tabindex="-1"></a>samp2</span></code></pre></div>
<pre><code>##  [1]  99.2  97.7  77.9  92.8 106.3 120.4  98.5 105.8  99.2  79.3  93.8  94.1  99.1 116.5 111.4
## [16]  97.5  96.2 110.5 108.3  89.7  89.4 105.5 111.5  98.3 113.2</code></pre>
<div class="sourceCode" id="cb1005"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1005-1"><a href="one-sample-inferential-statistics.html#cb1005-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(samp2)</span></code></pre></div>
<pre><code>## [1] 100.484</code></pre>
<p>This time the sample mean is <span class="math inline">\(\overline{x}=100.5\)</span>.</p>
<p>If you remember back to section <a href="distributions.html#what-is-a-sampling-distribution">7.2</a>, if we were to repeat this process thousands and thousands of times, we would get a <strong>sampling distribution of sample means</strong>. We could visualize all of our sample means from many thousands of samples in a histogram, which shows the shape of the sampling distribution:</p>
<p><img src="img/zt2.png" /></p>
<p>Because of Central Limit Theorem (see section <a href="distributions.html#central-limit-theorem">7.3</a>) then this sampling distribution is normally distributed and it’s mean <span class="math inline">\(\mu_{\overline{x}}\)</span> is equal to the population mean <span class="math inline">\(\mu\)</span>. Therefore <span class="math inline">\(\mu_{\overline{x}}=10.0\)</span>. We also know the standard deviation of this sampling distribution, also known as the <strong>standard error</strong> as it can be calculated by: <span class="math inline">\(\Large \sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}\)</span>. Therefore, the sampling distribution standard deviation is <span class="math inline">\(\sigma_{\overline{x}}=3.0\)</span>:</p>
<div class="sourceCode" id="cb1007"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1007-1"><a href="one-sample-inferential-statistics.html#cb1007-1" aria-hidden="true" tabindex="-1"></a>sem <span class="ot">&lt;-</span> <span class="dv">15</span> <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">25</span>)</span>
<span id="cb1007-2"><a href="one-sample-inferential-statistics.html#cb1007-2" aria-hidden="true" tabindex="-1"></a>sem</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>Because this sampling distribution is normally distributed, we can determine how far away from the mean any sample mean is in terms of how many standard deviations from the mean they are. For instance, our first sample we got a mean of <span class="math inline">\(\overline{x}=102.5\)</span>. How many sampling distribution standard deviations is this from the mean of the sampling distribution? We can use an amended z-score formula (see section <a href="distributions.html#z-scores">7.1</a>) to determine this:</p>
<p><span class="math inline">\(z = \frac{\overline{x} - \mu_{\overline{x}}}{\sigma_{\overline{x}}}\)</span></p>
<div class="sourceCode" id="cb1009"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1009-1"><a href="one-sample-inferential-statistics.html#cb1009-1" aria-hidden="true" tabindex="-1"></a>(<span class="fl">102.5</span> <span class="sc">-</span> <span class="fl">100.0</span>) <span class="sc">/</span> <span class="dv">3</span></span></code></pre></div>
<pre><code>## [1] 0.8333333</code></pre>
<p>So, our sample mean of <span class="math inline">\(\overline{x}=102.5\)</span> is 0.833 standard deviations above the mean. Because our sampling distribution is normally distributed, then we can visualize how far above the mean this value is on the standard normal curve as well as on the sampling distribution:</p>
<p><img src="img/zt3.png" /></p>
<p>If we were asked what proportion of sample means were at least as big as 102.5, then we’d be interested in knowing what proportion of sample means are to the right of the red lines above. We can calculate the area under a standard normal curve to the left of any <code>z</code> value in R using <code>pnorm()</code>:</p>
<div class="sourceCode" id="cb1011"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1011-1"><a href="one-sample-inferential-statistics.html#cb1011-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="fl">0.833</span>)</span></code></pre></div>
<pre><code>## [1] 0.7975776</code></pre>
<p>To find the proportion of the curve to the right of the red line (i.e. the proportion of sample means that are greater than 102.5), we just subtract this value from 1.</p>
<div class="sourceCode" id="cb1013"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1013-1"><a href="one-sample-inferential-statistics.html#cb1013-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">0.833</span>)</span></code></pre></div>
<pre><code>## [1] 0.2024224</code></pre>
<p>So 20.2% of samples have a sample mean greater than 102.5. In this situation, our one sample mean was not therefore that unusual or surprising.</p>
<p><br><br></p>
</div>
<div id="calculating-p-values-for-z-test" class="section level3" number="10.1.2">
<h3><span class="header-section-number">10.1.2</span> Calculating p-values for z-test</h3>
<p><strong>One-tailed tests</strong></p>
<p>We can calculate the proportion of sample means that are greater or less than any value. For instance, if we were interested in whether a new reading program in a school boosted the IQ of subjects. We might take a sample of 25 of these students and measure their IQ. If we got a sample mean of <span class="math inline">\(\overline{x}= 105.7\)</span>, we may wish to test whether this value is surprisingly large given that the population of IQ has a <span class="math inline">\(\mu=100.0\)</span> and <span class="math inline">\(\sigma=15.0\)</span>.</p>
<p>If we were to formally write this in hypothesis terms, it would look like this:</p>
<p><br>
<span class="math inline">\(H_{0}: \mu \le 100.0\)</span>
<br>
<span class="math inline">\(H_{1}: \mu &gt; 100.0\)</span>
<br></p>
<p>This is saying that the alternative hypothesis <span class="math inline">\(H_{1}\)</span> is that our sample of 25 come from a population whose mean is greater than 100.0. The null hypothesis that we are testing is that they come from a population whose mean is equal to or less than 100.0.</p>
<p>For the test, we assume with the null hypothesis that our sample did indeed come from a population with <span class="math inline">\(\mu=100.0\)</span> and <span class="math inline">\(\sigma=15.0\)</span>. We already calculated above that the sampling distribution of sample means for <span class="math inline">\(n=25\)</span> has a <span class="math inline">\(\mu_{\overline{x}}=100.0\)</span> and <span class="math inline">\(\sigma_{\overline{x}}=3.0\)</span>. How unusual is our one observed sample mean of <span class="math inline">\(\overline{x}=105.7\)</span>? We need to calculate this in terms of z:</p>
<p><span class="math inline">\(\Large z = \frac{\overline{x} - \mu_{\overline{x}}}{\sigma_{\overline{x}}}\)</span></p>
<div class="sourceCode" id="cb1015"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1015-1"><a href="one-sample-inferential-statistics.html#cb1015-1" aria-hidden="true" tabindex="-1"></a>(<span class="fl">105.7</span> <span class="sc">-</span> <span class="fl">100.0</span>) <span class="sc">/</span> <span class="dv">3</span></span></code></pre></div>
<pre><code>## [1] 1.9</code></pre>
<p>This suggests that our observed sample mean is 1.9 sampling distribution standard deviations away from the mean of the sampling distribution. We next need to work out what proportion of sample means are greater than this. That is akin to the red shaded area below:</p>
<p><img src="img/zt4.png" /></p>
<p>We can do this with <code>pnorm()</code>:</p>
<div class="sourceCode" id="cb1017"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1017-1"><a href="one-sample-inferential-statistics.html#cb1017-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">1.9</span>)</span></code></pre></div>
<pre><code>## [1] 0.02871656</code></pre>
<p>This shows that only 2.9% of sample means are greater than our observed sample mean, given the population data of <span class="math inline">\(\mu=100.0\)</span> and <span class="math inline">\(\sigma=15.0\)</span>. Therefore, our observed sample mean is quite surprising. We can write the likelihood of getting this sample mean as <code>p = 0.029</code>. Because we a priori had a prediction as to the direction of the mean in our sample (we predicted it to be higher than the population mean of 100.0), then we have in fact just done a one-tailed test. If we decide that any p-values that are below <code>p=0.05</code> are ‘significant’, then we can say that our reading program in the school has a ‘significant effect’ on improving IQ scores.</p>
<p><br><br></p>
<p><strong>Two-tailed tests</strong></p>
<p>What instead we had implement a reading program that was quite radical, and we were not sure whether it would be successful or not. We were interested in seeing whether it could increase or decrease IQ? In this situation, we do not have a direction of prediction, and we set up our hypotheses slightly differently:</p>
<p><br>
<span class="math inline">\(H_{0}: \mu = 100.0\)</span>
<br>
<span class="math inline">\(H_{1}: \mu \ne 100.0\)</span>
<br></p>
<p>Here, we are interested in whether our observed sample mean of <span class="math inline">\(\mu=105.7\)</span> could have come from a sampling distribution with a population mean of $_{=100.0} or not. The initial steps are the same. We calculate how unusual our observed sample mean was in terms of standard deviations away from the mean of the sampling distribution:</p>
<div class="sourceCode" id="cb1019"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1019-1"><a href="one-sample-inferential-statistics.html#cb1019-1" aria-hidden="true" tabindex="-1"></a>(<span class="fl">105.7</span> <span class="sc">-</span> <span class="fl">100.0</span>) <span class="sc">/</span> <span class="dv">3</span></span></code></pre></div>
<pre><code>## [1] 1.9</code></pre>
<p>It’s still 1.9 standard deviations away.</p>
<p>What we have to now thing about, is that because we did not predict the direction of the difference, we have to double our p-value. This is to account for the fact that in terms of ‘surprising’ results, we are interested in results that are more extreme than 1.9 standard deviations either side of the mean - i.e. the sum of the shaded area below:</p>
<p><img src="img/zt5.png" /></p>
<p>Therefore, our p-value for this test is:</p>
<div class="sourceCode" id="cb1021"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1021-1"><a href="one-sample-inferential-statistics.html#cb1021-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">1.9</span>))</span></code></pre></div>
<pre><code>## [1] 0.05743312</code></pre>
<p>Which is <code>p=0.057</code>. This would suggest that our reading program did not sufficiently shift the population IQ scores in our school away from 100.0, as our p-value is greater than 0.05.</p>
<p>But is this really true? It is important to consider two things here. One, it is important what initial hypothesis that you set up. If you have a strong a priori belief in the directionality of the hypothesis, then you are justified in doing a one-tailed z-test and using that p-value from that. Secondly, the difference between <code>p=0.029</code> and <code>p=0.057</code> in this case isn’t that great. We shouldn’t be overly focused on the cut-off value of <code>p=0.05</code> as the criteria as to whether our results are significant or not significant. We should see the bigger picture, that our p-value is just one piece of information as to how different our sample of data is from the population that we believe it came from.</p>
<p><br><br></p>
</div>
<div id="using-critical-values" class="section level3" number="10.1.3">
<h3><span class="header-section-number">10.1.3</span> Using critical values</h3>
<p>In the preceding section, we ran one-tailed and two-tailed z-tests and calculated exact p-values. It is reasonably straightforward to do this in R. There is no reason not to use that approach. We prefer it. However, most often in introductory textbooks, a different approach is used. In this approach, the step of calculating the p-value is missed out. Instead, you are asked to just determine whether your observed z-value is more extreme than you’d expect by chance. “By chance” in this context means, that your observed z-value is less than 5% likely to occur.</p>
<p><br></p>
<p><strong>One-tailed z-test</strong></p>
<p>The population mean for SAT scores is <span class="math inline">\(\mu=500\)</span> with a population standard deviation <span class="math inline">\(\sigma=100\)</span>. A tutoring company says that they improve SAT scores. A random sample of 12 students who took the tutoring program had a sample mean of <span class="math inline">\(\overline(x)=551\)</span>. Let’s test whether this sample mean came from the population.</p>
<p><br>
<span class="math inline">\(H_{0}: \mu \le 500.0\)</span>
<br>
<span class="math inline">\(H_{1}: \mu &gt; 500.0\)</span>
<br></p>
<p>Next, we calculate the mean and standard deviation of the sampling distribution for a sample size <span class="math inline">\(n=12\)</span>. For the test, we assume that the sampling distribution mean <span class="math inline">\(\mu_{\overline{x}}=500.0\)</span> - i.e. is the same as the population mean. The standard deviation of the sampling distribution <span class="math inline">\(\sigma_{\overline{x}} = 28.87\)</span>:</p>
<div class="sourceCode" id="cb1023"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1023-1"><a href="one-sample-inferential-statistics.html#cb1023-1" aria-hidden="true" tabindex="-1"></a><span class="dv">100</span> <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">12</span>)</span></code></pre></div>
<pre><code>## [1] 28.86751</code></pre>
<p>Next, we work out how many sampling distribution standard deviations from the sampling distribution mean is our observed sample:</p>
<div class="sourceCode" id="cb1025"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1025-1"><a href="one-sample-inferential-statistics.html#cb1025-1" aria-hidden="true" tabindex="-1"></a>(<span class="dv">551</span> <span class="sc">-</span> <span class="dv">500</span>) <span class="sc">/</span> <span class="fl">28.86751</span></span></code></pre></div>
<pre><code>## [1] 1.766692</code></pre>
<p>This shows that our observed sample mean of <span class="math inline">\(\overline{x}=551\)</span> is 1.77 standard deviations above the mean of the sampling distribution. We could convert this to a p-value and calculate precisely how many sample means are larger than this in the sampling distribution. Instead, we’ll take a different approach:</p>
<p>Because this sampling distribution is approximately normal, we can determine how many standard deviations above the mean you’d have to be to be larger than 95% of all samples.</p>
<p><img src="img/zt6.png" /></p>
<p>It turns out that <span class="math inline">\(z=1.645\)</span> is the value of <span class="math inline">\(z\)</span> that leaves 5% in the right hand tail. Therefore, any value of <span class="math inline">\(z\)</span> greater than <span class="math inline">\(z=1.645\)</span> will be ‘unusually’ large and have a p-value of less than 0.05. If we were dealing with sample means that were surprisingly small (so a one-tailed test where we are predicting that the sample mean comes from a population with a mean that is smaller than the population mean), then we are looking for <span class="math inline">\(z\)</span> values that are lower than <span class="math inline">\(z=-1.645\)</span>.</p>
<p>We can work out where these ‘critical values’ are in R using the <code>qnorm()</code> function:</p>
<div class="sourceCode" id="cb1027"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1027-1"><a href="one-sample-inferential-statistics.html#cb1027-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.95</span>) <span class="co"># leaves 5% in right of tail</span></span></code></pre></div>
<pre><code>## [1] 1.644854</code></pre>
<div class="sourceCode" id="cb1029"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1029-1"><a href="one-sample-inferential-statistics.html#cb1029-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.05</span>) <span class="co"># leaves 5% in left of tail</span></span></code></pre></div>
<pre><code>## [1] -1.644854</code></pre>
<p>If we get back to our observed <span class="math inline">\(z\)</span> value of <span class="math inline">\(z=1.77\)</span>, we can overlay this over the graph above like this:</p>
<p><img src="img/zt7.png" /></p>
<p>As you can see, our observed <span class="math inline">\(z\)</span> value is more extreme than the ‘critical value’ of <span class="math inline">\(z=1.645\)</span>. We say that our observed value is therefore in the ‘region of rejection’ and we can therefore reject the null hypothesis with a p-value of <span class="math inline">\(p&lt;0.05\)</span> and accept the alternate hypothesis that our sample comes from a population with a population mean that is greater than 500. In other words, the tutoring program appears to have a population mean of SAT scores greater than 500.</p>
<p><br><br></p>
<p><strong>Two-tailed z-test</strong></p>
<p>With the one-tailed z-test, we see that our critical values of z are <span class="math inline">\(z=1.645\)</span> for situations in which we are testing whether our sample mean is unexpectedly large, or <span class="math inline">\(z=-1.645\)</span> for situations in which we are testing that our sample mean is unexpectedly small. In a two-tailed situation, we are testing whether our sample mean is unexpectedly large <em>or</em> small. Because we still want only 5% of sample means to be in this ‘unexpectedly’ large or small category, this time we need a value of <span class="math inline">\(z\)</span> that leaves a total of 5% in the ends of both tails of the normal distribution. This is the same as leaving 2.5% in each tail:</p>
<p><img src="img/zt8.png" /></p>
<div class="sourceCode" id="cb1031"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1031-1"><a href="one-sample-inferential-statistics.html#cb1031-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(.<span class="dv">975</span>)  <span class="co"># leaves 2.5% in right tail</span></span></code></pre></div>
<pre><code>## [1] 1.959964</code></pre>
<div class="sourceCode" id="cb1033"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1033-1"><a href="one-sample-inferential-statistics.html#cb1033-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(.<span class="dv">025</span>)  <span class="co"># leaves 2.5% in left tail</span></span></code></pre></div>
<pre><code>## [1] -1.959964</code></pre>
<p>Let’s illustrate this a bit further with the following example. Say we have a bakery that makes cupcakes. The population mean weight of cupcakes is <span class="math inline">\(\mu=6.5\)</span> ounces, with a standard deviation of <span class="math inline">\(\sigma=0.15\)</span> ounces. A customer wants to test if a new cupcake variety is heavier or lighter than 6.5 ounces. They purchase a random sample of 10 cupcakes and find that the sample mean is <span class="math inline">\(\overline(x)=6.42\)</span> ounces.</p>
<p>If we were to conduct a two-tailed test, to test if the population mean that our sample come from is equal to 6.5 ounces or not, then our hypotheses would be:</p>
<p><br>
<span class="math inline">\(H_{0}: \mu = 6.5\)</span>
<br>
<span class="math inline">\(H_{1}: \mu \ne 6.5\)</span>
<br></p>
<p>We need to calculate the z-score for our sample mean, to determine how many standard deviations of the sampling distribution it is away from the mean.</p>
<div class="sourceCode" id="cb1035"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1035-1"><a href="one-sample-inferential-statistics.html#cb1035-1" aria-hidden="true" tabindex="-1"></a>sem <span class="ot">&lt;-</span> <span class="fl">0.15</span> <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">10</span>)  <span class="co">#standard deviation of the sampling distribution</span></span>
<span id="cb1035-2"><a href="one-sample-inferential-statistics.html#cb1035-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1035-3"><a href="one-sample-inferential-statistics.html#cb1035-3" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> (<span class="fl">6.42</span> <span class="sc">-</span> <span class="fl">6.5</span>) <span class="sc">/</span> sem  <span class="co"># how many SD away from the mean is our sample</span></span>
<span id="cb1035-4"><a href="one-sample-inferential-statistics.html#cb1035-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1035-5"><a href="one-sample-inferential-statistics.html#cb1035-5" aria-hidden="true" tabindex="-1"></a>z</span></code></pre></div>
<pre><code>## [1] -1.686548</code></pre>
<p>We can overlay this observed value of <span class="math inline">\(z\)</span> onto our standard normal curve like this:</p>
<p><img src="img/zt9.png" /></p>
<p>Our value of <span class="math inline">\(z=-1.69\)</span> is therefore not inside either of the regions of rejection. This means that we do not have sufficient evidence to reject the null hypothesis that our sample comes from a population with mean of equal to 6.5.</p>
<p><br><br></p>
</div>
</div>
<div id="one-sample-t-tests" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> One-sample t-tests</h2>
<p>As with confidence intervals based on the <span class="math inline">\(z\)</span>-distribution (the standard normal curve), the major issue with z-tests is that they require you to know the population mean <span class="math inline">\(\sigma\)</span> to perform the calculations. This is almost never the case - with exceptions like standardized tests including IQ and SAT that are designed to have specific means and standard deviations.</p>
<p>If you wish to test whether your observed sample mean is likely or not to come from a population with a given mean, what approach should you take when you do not know <span class="math inline">\(\sigma\)</span>? As with confidence intervals, the approach we take is to use the <span class="math inline">\(t\)</span>-distribution.</p>
<p>In this situation, because we don’t know our population standard deviation <span class="math inline">\(\sigma\)</span>, we have to estimate it using the sample standard deviation <span class="math inline">\(s\)</span>. Further, because our sampling distribution may not be precisely normal given this estimation, we say that it comes from a <span class="math inline">\(t\)</span>-distribution. <span class="math inline">\(t\)</span>-distributions have slightly heavier tails than the normal distribution.</p>
<p><br><br></p>
<p><strong>One-tailed t-test example</strong></p>
<p>Let’s illustrate the steps we take in a one-sample t-test with an example. These steps are identical to the two-tailed t-test up until we calculate the p-value.</p>
<p>The population mean number of words spoken by two year olds by their 2nd birthday is <span class="math inline">\(\mu=50\)</span> words and this is normally distributed. We don’t know the population standard deviation <span class="math inline">\(\sigma\)</span>. A researcher wanted to investigate if reading to children increases their word knowledge. They collected data from 12 children (<span class="math inline">\(n=12\)</span>) who were read to for at least two hours every day. These are the number of words spoken by the 12 children:</p>
<div class="sourceCode" id="cb1037"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1037-1"><a href="one-sample-inferential-statistics.html#cb1037-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">45</span>, <span class="dv">53</span>, <span class="dv">71</span>, <span class="dv">35</span>, <span class="dv">51</span>, <span class="dv">59</span>, <span class="dv">49</span>, <span class="dv">55</span>, <span class="dv">78</span>, <span class="dv">27</span>, <span class="dv">66</span>, <span class="dv">59</span>)</span>
<span id="cb1037-2"><a href="one-sample-inferential-statistics.html#cb1037-2" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>##  [1] 45 53 71 35 51 59 49 55 78 27 66 59</code></pre>
<div class="sourceCode" id="cb1039"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1039-1"><a href="one-sample-inferential-statistics.html#cb1039-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)  </span></code></pre></div>
<pre><code>## [1] 54</code></pre>
<p>Our one observed sample mean <span class="math inline">\(\overline{x}=54\)</span>. This is higher than 50, but is it meaningfully higher? If we were to formalize our hypothesis for this test, we would write:</p>
<p><br>
<span class="math inline">\(H_{0}: \mu \le 50.0\)</span>
<br>
<span class="math inline">\(H_{1}: \mu &gt; 50.0\)</span>
<br></p>
<p>We are testing whether our sample was likely to have come from a population with mean 50 or less (null hypothesis), or if it was more likely to come from a population with a mean of greater than 50.</p>
<p>The first step is to think about the sampling distribution. We need to recognize that our one observed sample mean is just one sample mean that we theoretically could have got from a sample distribution. Under the null hypothesis, we are going to assume that the mean of our sampling distribution <span class="math inline">\(\mu_{\overline{x}}\)</span> is equivalent to the population mean <span class="math inline">\(\mu\)</span>. Therefore, <span class="math inline">\(\mu_{\overline{x}}=50.0\)</span></p>
<p>Next, we need to calculate the standard deviation of the sampling distribution of sample means for n=12 (i.e. the standard error). As we do not know the population standard deviation <span class="math inline">\(\sigma\)</span>, we estimate this by using the following formula:</p>
<p><span class="math inline">\(\Large \sigma_{\overline{x}} = \frac{s}{\sqrt{n}}\)</span></p>
<p>Therefore, our estimate of the standard error is <span class="math inline">\(\sigma_{\overline{x}}=4.14\)</span>:</p>
<div class="sourceCode" id="cb1041"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1041-1"><a href="one-sample-inferential-statistics.html#cb1041-1" aria-hidden="true" tabindex="-1"></a>sem <span class="ot">&lt;-</span> <span class="fu">sd</span>(x) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">12</span>)</span>
<span id="cb1041-2"><a href="one-sample-inferential-statistics.html#cb1041-2" aria-hidden="true" tabindex="-1"></a>sem</span></code></pre></div>
<pre><code>## [1] 4.143268</code></pre>
<p>Now that we know both the mean and standard deviation of the t-shaped sampling distribution, next we need to calculate how many standard deviations from this mean is our one observed sample mean. We calculate that using the formula that is similar to the <span class="math inline">\(z\)</span> formula:</p>
<p><span class="math inline">\(\Large t = \frac{\overline{x} - \mu_{\overline{x}}}{\sigma_{\overline{x}}}\)</span></p>
<p>Our sample mean of <span class="math inline">\(\overline{x}=54\)</span> has a <span class="math inline">\(t\)</span> value of <span class="math inline">\(t = 0.965\)</span>:</p>
<div class="sourceCode" id="cb1043"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1043-1"><a href="one-sample-inferential-statistics.html#cb1043-1" aria-hidden="true" tabindex="-1"></a>(<span class="dv">54-50</span>) <span class="sc">/</span> sem</span></code></pre></div>
<pre><code>## [1] 0.9654216</code></pre>
<p>This means that it is approximately 0.965 standard deviations higher than the mean. We can calculate the proportion of sample means in the sampling distribution that are higher than our one observed sample mean by calculating the area under the curve to the right of our <span class="math inline">\(t\)</span>-value. Remember, that our sampling distribution is <span class="math inline">\(t\)</span>-shaped and has 11 degrees of freedom. The degrees of freedom are <span class="math inline">\(df = n-1\)</span> for a one-sample t-test.</p>
<p><img src="img/tt1.png" /></p>
<p>To determine what proportion of the curve lies to the right of <span class="math inline">\(t=0.965\)</span> we can use <code>pt()</code> which calculates the proportion to the left of the given value.</p>
<div class="sourceCode" id="cb1045"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1045-1"><a href="one-sample-inferential-statistics.html#cb1045-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pt</span>(<span class="fl">0.965</span>, <span class="at">df=</span><span class="dv">11</span>)</span></code></pre></div>
<pre><code>## [1] 0.8223595</code></pre>
<p>So, this tells us that for a <span class="math inline">\(t\)</span>-distribution with 11 degrees of freedom, that 82.2% of values are to the left (lower than) of this value. That means that 17.8% of values are to the right, or 17.8% of sample means that could be drawn from the sampling distribution with a mean of 54 and standard deviation of 4.14 will be higher than our observed sample mean.</p>
<div class="sourceCode" id="cb1047"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1047-1"><a href="one-sample-inferential-statistics.html#cb1047-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pt</span>(<span class="fl">0.965</span>, <span class="at">df=</span><span class="dv">11</span>)</span></code></pre></div>
<pre><code>## [1] 0.1776405</code></pre>
<p>We can also get this value by setting <code>lower.tail = FALSE</code>:</p>
<div class="sourceCode" id="cb1049"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1049-1"><a href="one-sample-inferential-statistics.html#cb1049-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pt</span>(<span class="fl">0.965</span>, <span class="at">df=</span><span class="dv">11</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>) </span></code></pre></div>
<pre><code>## [1] 0.1776405</code></pre>
<p>Because we made a prediction as to the direction of the hypothesis - i.e. we predicted that reading to children would <em>increase</em> the population mean, we are effectively running a one-tailed test. Our p-value is simply <span class="math inline">\(p=0.177\)</span>. As we use an alpha level of 0.05 (a p-value of 0.05 as our critical value), this suggests that we do not have sufficient evidence to suggest that our sample of 12 children have a mean value that comes from a population with a mean that is greater than 50. We do not reject our null hypothesis.</p>
<p><br><br></p>
<p><strong>Two-tailed t-test example</strong></p>
<p>There are 20 psychology students in Dr. Zeppo’s class. Here are their scores on a test, as well as their sample mean <span class="math inline">\(\overline{x}\)</span> and sample standard deviation <span class="math inline">\(s\)</span>:</p>
<div class="sourceCode" id="cb1051"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1051-1"><a href="one-sample-inferential-statistics.html#cb1051-1" aria-hidden="true" tabindex="-1"></a>zeppo <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">60</span>,<span class="dv">60</span>,<span class="dv">64</span>,<span class="dv">66</span>,<span class="dv">66</span>,<span class="dv">67</span>,<span class="dv">69</span>,<span class="dv">70</span>,<span class="dv">74</span>,<span class="dv">76</span>,<span class="dv">76</span>,<span class="dv">77</span>,<span class="dv">79</span>,<span class="dv">79</span>,<span class="dv">79</span>,<span class="dv">81</span>,<span class="dv">82</span>,<span class="dv">82</span>,<span class="dv">89</span>)</span>
<span id="cb1051-2"><a href="one-sample-inferential-statistics.html#cb1051-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1051-3"><a href="one-sample-inferential-statistics.html#cb1051-3" aria-hidden="true" tabindex="-1"></a>zeppo</span></code></pre></div>
<pre><code>##  [1] 50 60 60 64 66 66 67 69 70 74 76 76 77 79 79 79 81 82 82 89</code></pre>
<div class="sourceCode" id="cb1053"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1053-1"><a href="one-sample-inferential-statistics.html#cb1053-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(zeppo)  <span class="co"># 20 - there are 20 students in the sample.</span></span></code></pre></div>
<pre><code>## [1] 20</code></pre>
<div class="sourceCode" id="cb1055"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1055-1"><a href="one-sample-inferential-statistics.html#cb1055-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(zeppo)  <span class="co"># the mean of the sample is 72.3</span></span></code></pre></div>
<pre><code>## [1] 72.3</code></pre>
<div class="sourceCode" id="cb1057"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1057-1"><a href="one-sample-inferential-statistics.html#cb1057-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(zeppo)  <span class="co"># the sample SD is 9.52</span></span></code></pre></div>
<pre><code>## [1] 9.520615</code></pre>
<p>Historically, students in this class get a score of 65 points on this test - that is the population mean <span class="math inline">\(\mu\)</span>. Dr Zeppo wishes to test if this one sample (one class) has a mean (technically ‘comes from a population with a mean’) that is different to 65. We would write out this hypothesis like this:</p>
<p><br>
<span class="math inline">\(H_{0}: \mu = 65.0\)</span>
<br>
<span class="math inline">\(H_{1}: \mu \ne 65.0\)</span>
<br></p>
<p>As with all of these tests, our first job is to recognize that our one sample mean is just one sample mean that we ‘theoretically’ could have got from lots of samples of size <span class="math inline">\(n=20\)</span>. All of those sample means together are referred to as the sampling distribution of sample means. Under the null hypothesis, we assume that the mean of the sampling distribution of sample means <span class="math inline">\(\mu_{\overline{x}}=65\)</span>, i.e. it is equivalent to the population mean <span class="math inline">\(\mu\)</span>. Next, we have to estimate the standard deviation of the sampling distribution of sample means, i.e. the standard error <span class="math inline">\(\sigma_{\overline{x}}\)</span>. We do this using the same formula as before:</p>
<p><span class="math inline">\(\large \sigma_{\overline{x}} = \frac{s}{\sqrt{n}}\)</span></p>
<p>So, our standard error is <span class="math inline">\(\sigma_{\overline{x}} = 2.13\)</span>:</p>
<div class="sourceCode" id="cb1059"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1059-1"><a href="one-sample-inferential-statistics.html#cb1059-1" aria-hidden="true" tabindex="-1"></a>sem <span class="ot">&lt;-</span> <span class="fu">sd</span>(zeppo) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">20</span>)</span>
<span id="cb1059-2"><a href="one-sample-inferential-statistics.html#cb1059-2" aria-hidden="true" tabindex="-1"></a>sem</span></code></pre></div>
<pre><code>## [1] 2.128874</code></pre>
<p>Following this, we need to calculate how expected or unexpected our one sample mean <span class="math inline">\(\overline{x}\)</span> was. We do this by calculating it in terms of how many sampling distribution standard deviations is it away from the sampling distribution mean. We use the formula:</p>
<p><span class="math inline">\(\Large t = \frac{\overline{x} - \mu_{\overline{x}}}{\sigma_{\overline{x}}}\)</span></p>
<div class="sourceCode" id="cb1061"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1061-1"><a href="one-sample-inferential-statistics.html#cb1061-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">mean</span>(zeppo) <span class="sc">-</span> <span class="dv">65</span>) <span class="sc">/</span> sem</span></code></pre></div>
<pre><code>## [1] 3.429042</code></pre>
<p>Our observed sample mean of <span class="math inline">\(\overline{x} = 72.3\)</span> is 3.43 sampling distribution standard deviations from the sampling distribution mean.</p>
<p>We can picture this as follows:
<br></p>
<p><img src="img/tt2.png" /></p>
<p>To calculate our p-value for our 2-tailed t-test, we need to calculate not just the area underneath the curve with values of <span class="math inline">\(t\)</span> greater than our observed <span class="math inline">\(t=3.43\)</span>, but also the values under the curve with <span class="math inline">\(t\)</span> values that are more negative than <span class="math inline">\(t=-3.43\)</span>. This is because in a 2-tailed test, we need to test for the probability of getting a <span class="math inline">\(t\)</span>-value as large in both directions. Our p-value can be calculated using <code>pt()</code>:</p>
<div class="sourceCode" id="cb1063"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1063-1"><a href="one-sample-inferential-statistics.html#cb1063-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pt</span>(<span class="fl">3.43</span>, <span class="at">df =</span> <span class="dv">19</span>, <span class="at">lower.tail =</span> F) <span class="sc">+</span> <span class="fu">pt</span>(<span class="sc">-</span><span class="fl">3.43</span>, <span class="at">df =</span> <span class="dv">19</span>) </span></code></pre></div>
<pre><code>## [1] 0.002807258</code></pre>
<p>Or alternatively, we could just multiply those values greater than <span class="math inline">\(t=3.43\)</span> by 2:</p>
<div class="sourceCode" id="cb1065"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1065-1"><a href="one-sample-inferential-statistics.html#cb1065-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pt</span>(<span class="fl">3.43</span>, <span class="at">df =</span> <span class="dv">19</span>, <span class="at">lower.tail =</span> F) <span class="sc">*</span> <span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 0.002807258</code></pre>
<p>Either way, we can see that our p-values is <span class="math inline">\(p = 0.003\)</span>, which tells us that our observed mean of <span class="math inline">\(\overline{x}=72.3\)</span> is quite unlikely to have come from a distribution with a population mean <span class="math inline">\(\mu=65\)</span>. This leads us to rejecting our null hypothesis and accepting the alternative, that these psychology students come from a population with a mean that is greater than 65.</p>
<p><br><br></p>
<div id="critical-values-for-the-one-sample-t-test" class="section level3" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> Critical values for the one-sample t-test</h3>
<p>As with the z-test (see section <a href="#one-sample-z-test"><strong>??</strong></a>, instead of calculating the p-values for our observed values of <span class="math inline">\(t\)</span>, you can simply test whether your value of <span class="math inline">\(t\)</span> exceeds (in either the positive or negative direction) some ‘critical value’ of <span class="math inline">\(t\)</span>. Again, this approach was more often taken when it wasn’t as easy to run computers to do these tests, so it seems a bit obsolete to do it this way. We recommend just doing it the way outlined above. Nevertheless, just for completeness, here is how to calculate these critical values of <span class="math inline">\(t\)</span>.</p>
<p>We’ll use data from a different dataset. Here, we have the times taken to complete a crossword puzzle. We have a sample of <span class="math inline">\(n=10\)</span> subjects.</p>
<div class="sourceCode" id="cb1067"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1067-1"><a href="one-sample-inferential-statistics.html#cb1067-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1067-2"><a href="one-sample-inferential-statistics.html#cb1067-2" aria-hidden="true" tabindex="-1"></a>xt <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/crosstimes.csv&quot;</span>)</span>
<span id="cb1067-3"><a href="one-sample-inferential-statistics.html#cb1067-3" aria-hidden="true" tabindex="-1"></a>xt<span class="sc">$</span>time3</span></code></pre></div>
<pre><code>##  [1] 15.04036 15.38213 15.70967 14.71215 12.18972 19.90511 20.00015 12.45357 12.86255 12.82682</code></pre>
<p>Let’s say we wish to test whether this sample comes from a population with a mean of less than 16.0. We would be doing a one-tailed test and our hypotheses would look like this:</p>
<p><br>
<span class="math inline">\(H_{0}: \mu \ge 16.0\)</span>
<br>
<span class="math inline">\(H_{1}: \mu &lt; 16.0\)</span>
<br></p>
<p>When using critical values, all the steps up to completing the observed <span class="math inline">\(t\)</span>-value are the same as before. So, we assume that our one sample mean <span class="math inline">\(\overline{x}\)</span> comes from a sampling distribution of sample means that has a mean equivalent to the population mean of 16. The standard deviation of this sampling distribution is:</p>
<div class="sourceCode" id="cb1069"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1069-1"><a href="one-sample-inferential-statistics.html#cb1069-1" aria-hidden="true" tabindex="-1"></a>sem <span class="ot">&lt;-</span> <span class="fu">sd</span>(xt<span class="sc">$</span>time3) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">10</span>)</span>
<span id="cb1069-2"><a href="one-sample-inferential-statistics.html#cb1069-2" aria-hidden="true" tabindex="-1"></a>sem</span></code></pre></div>
<pre><code>## [1] 0.9027857</code></pre>
<p>Next, we calculate our observed <span class="math inline">\(t\)</span> which is a measure of how many sampling deviation standard deviations our observed sample mean is away from the mean of the sampling distribution:</p>
<div class="sourceCode" id="cb1071"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1071-1"><a href="one-sample-inferential-statistics.html#cb1071-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">mean</span>(xt<span class="sc">$</span>time3) <span class="sc">-</span> <span class="dv">16</span>) <span class="sc">/</span> sem</span></code></pre></div>
<pre><code>## [1] -0.9878071</code></pre>
<p>Our observed <span class="math inline">\(t\)</span> values is <span class="math inline">\(t = -0.99\)</span>.</p>
<p>As we are conducting a one-tailed t-test, we need to think in terms of what value of <span class="math inline">\(t\)</span> leaves 5% in the tail for a t-distribution with 9 degrees of freedom. This is visualized below:</p>
<p><img src="img/tt3.png" /></p>
<p>If our observed sample mean with a <span class="math inline">\(t\)</span>-value of -0.99 was unexpectedly small, then it would need to be in the region of rejection (red shaded area). This would mean that it was in the bottom 5% of sample means from such a distribution. The value of <span class="math inline">\(t\)</span> that is the boundary of the the lower 5% can be calculated using the <code>qt()</code> function like this:</p>
<div class="sourceCode" id="cb1073"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1073-1"><a href="one-sample-inferential-statistics.html#cb1073-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.05</span>, <span class="at">df=</span><span class="dv">9</span>)</span></code></pre></div>
<pre><code>## [1] -1.833113</code></pre>
<p><br><br></p>
<p><strong>Two-tailed tests</strong></p>
<p>For this example, let’s use the <code>penguins</code> data. Say we are interested in the flipper length of male Adelie penguins on Biscoe island (a bit specific, but let’s go with it), and wanted to know if their mean length was different from <span class="math inline">\(\mu = 188\)</span>. Our hypotheses would be:</p>
<p><br>
<span class="math inline">\(H_{0}: \mu = 188.0\)</span>
<br>
<span class="math inline">\(H_{1}: \mu \ne 188.0\)</span>
<br></p>
<p>From our data, we can calculate our <span class="math inline">\(n\)</span> and sample mean <span class="math inline">\(\overline{x}\)</span>:</p>
<div class="sourceCode" id="cb1075"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1075-1"><a href="one-sample-inferential-statistics.html#cb1075-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Read in the Data Penguins</span></span>
<span id="cb1075-2"><a href="one-sample-inferential-statistics.html#cb1075-2" aria-hidden="true" tabindex="-1"></a>penguins <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/penguins.csv&quot;</span>)</span>
<span id="cb1075-3"><a href="one-sample-inferential-statistics.html#cb1075-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1075-4"><a href="one-sample-inferential-statistics.html#cb1075-4" aria-hidden="true" tabindex="-1"></a><span class="co"># just look at the females.</span></span>
<span id="cb1075-5"><a href="one-sample-inferential-statistics.html#cb1075-5" aria-hidden="true" tabindex="-1"></a>adelie <span class="ot">&lt;-</span> penguins <span class="sc">%&gt;%</span> <span class="fu">filter</span>(species <span class="sc">==</span> <span class="st">&quot;Adelie&quot;</span>, sex <span class="sc">==</span> <span class="st">&quot;MALE&quot;</span>, island <span class="sc">==</span> <span class="st">&quot;Biscoe&quot;</span>)</span>
<span id="cb1075-6"><a href="one-sample-inferential-statistics.html#cb1075-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1075-7"><a href="one-sample-inferential-statistics.html#cb1075-7" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(adelie)</span></code></pre></div>
<pre><code>## [1] 22</code></pre>
<div class="sourceCode" id="cb1077"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1077-1"><a href="one-sample-inferential-statistics.html#cb1077-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(adelie<span class="sc">$</span>flipper_length_mm)</span></code></pre></div>
<pre><code>## [1] 190.4091</code></pre>
<p>We can also represent these data as a boxplot:</p>
<div class="sourceCode" id="cb1079"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1079-1"><a href="one-sample-inferential-statistics.html#cb1079-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(adelie, <span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> flipper_length_mm)) <span class="sc">+</span></span>
<span id="cb1079-2"><a href="one-sample-inferential-statistics.html#cb1079-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb1079-3"><a href="one-sample-inferential-statistics.html#cb1079-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">width =</span> .<span class="dv">1</span>, <span class="at">size=</span><span class="dv">2</span>)<span class="sc">+</span></span>
<span id="cb1079-4"><a href="one-sample-inferential-statistics.html#cb1079-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.title.y=</span><span class="fu">element_blank</span>(),</span>
<span id="cb1079-5"><a href="one-sample-inferential-statistics.html#cb1079-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y=</span><span class="fu">element_blank</span>(),</span>
<span id="cb1079-6"><a href="one-sample-inferential-statistics.html#cb1079-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y=</span><span class="fu">element_blank</span>()) <span class="sc">+</span></span>
<span id="cb1079-7"><a href="one-sample-inferential-statistics.html#cb1079-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb1079-8"><a href="one-sample-inferential-statistics.html#cb1079-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">187</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-475-1.png" width="576" /></p>
<p>Our sample of penguins has a sample size of <span class="math inline">\(n=22\)</span>, with a sample mean of <span class="math inline">\(\overline{x}=190.4\)</span>. Let’s calculate our observed value of <span class="math inline">\(t\)</span> for this sample:</p>
<div class="sourceCode" id="cb1080"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1080-1"><a href="one-sample-inferential-statistics.html#cb1080-1" aria-hidden="true" tabindex="-1"></a>sem <span class="ot">&lt;-</span> <span class="fu">sd</span>(adelie<span class="sc">$</span>flipper_length_mm) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">22</span>)</span>
<span id="cb1080-2"><a href="one-sample-inferential-statistics.html#cb1080-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1080-3"><a href="one-sample-inferential-statistics.html#cb1080-3" aria-hidden="true" tabindex="-1"></a>tobs <span class="ot">&lt;-</span> (<span class="fu">mean</span>(adelie<span class="sc">$</span>flipper_length_mm) <span class="sc">-</span> <span class="dv">188</span>) <span class="sc">/</span> sem</span>
<span id="cb1080-4"><a href="one-sample-inferential-statistics.html#cb1080-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1080-5"><a href="one-sample-inferential-statistics.html#cb1080-5" aria-hidden="true" tabindex="-1"></a>tobs</span></code></pre></div>
<pre><code>## [1] 1.748218</code></pre>
<p>This means that our observed sample mean is 1.75 sample standard deviations above the sampling distribution mean.</p>
<p>In terms of critical regions, for a 2-tailed test, we need to know the values of <span class="math inline">\(t\)</span> that leave 2.5% in each tail for a <span class="math inline">\(t\)</span>-distribution with 21 degrees of freedom.</p>
<div class="sourceCode" id="cb1082"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1082-1"><a href="one-sample-inferential-statistics.html#cb1082-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(.<span class="dv">975</span>, <span class="at">df =</span> <span class="dv">21</span>)</span></code></pre></div>
<pre><code>## [1] 2.079614</code></pre>
<div class="sourceCode" id="cb1084"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1084-1"><a href="one-sample-inferential-statistics.html#cb1084-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(.<span class="dv">025</span>, <span class="at">df =</span> <span class="dv">21</span>)</span></code></pre></div>
<pre><code>## [1] -2.079614</code></pre>
<p><br></p>
<p><img src="img/tt4.png" /></p>
<p>For a <span class="math inline">\(t\)</span>-distribution with 21 degrees of freedom, the top 2.5% of t-values are greater than <span class="math inline">\(t=2.08\)</span>, whilst the lowest 2.5% of t-values are below <span class="math inline">\(t=-2.08\)</span>. Therefore, for us to reject the null hypothesis, our observed t-value needs to be higher than 2.08 or lower than -2.08. That would leave it in the region of rejection (red shaded areas above). Our observed t-value is <span class="math inline">\(t=1.75\)</span> which is not in these areas, so we cannot reject the null hypothesis. We do not have sufficient evidence to suggest that our penguins come from a population with a mean of <span class="math inline">\(\mu = 188\)</span>.</p>
<p><br><br></p>
</div>
</div>
<div id="conducting-one-sample-t-tests-in-r" class="section level2" number="10.3">
<h2><span class="header-section-number">10.3</span> Conducting one-sample t-tests in R</h2>
<p>Conducting one-sample t-tests in R is very straightforward.</p>
<p>First, let’s consider the sample of 12 two-year olds and their word scores.</p>
<div class="sourceCode" id="cb1086"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1086-1"><a href="one-sample-inferential-statistics.html#cb1086-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">45</span>, <span class="dv">53</span>, <span class="dv">71</span>, <span class="dv">35</span>, <span class="dv">51</span>, <span class="dv">59</span>, <span class="dv">49</span>, <span class="dv">55</span>, <span class="dv">78</span>, <span class="dv">27</span>, <span class="dv">66</span>, <span class="dv">59</span>)</span>
<span id="cb1086-2"><a href="one-sample-inferential-statistics.html#cb1086-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span></code></pre></div>
<pre><code>## [1] 54</code></pre>
<p>To test whether this sample mean is likely to have come from a population with a mean greater than 50, we use <code>t.test()</code> in the following way:</p>
<div class="sourceCode" id="cb1088"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1088-1"><a href="one-sample-inferential-statistics.html#cb1088-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(x, <span class="at">mu =</span> <span class="dv">50</span>, <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span>)  <span class="co"># one-tailed test</span></span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = 0.96542, df = 11, p-value = 0.1775
## alternative hypothesis: true mean is greater than 50
## 95 percent confidence interval:
##  46.55917      Inf
## sample estimates:
## mean of x 
##        54</code></pre>
<p><code>mu</code> specifies the mean that we are testing against. <code>alternative = "greater"</code> states that it is a one-tailed test, where we are testing the prediction that the population mean is greater than 50. The output gives us the same observed t-value that we calculated by hand <span class="math inline">\(t=0.97\)</span>, the degrees of freedom and the p-value.</p>
<p>To conduct a two-tailed test, where we just make the prediction that the population mean that the sample came from is not equal to some value, we just drop the <code>alternative</code> argument. For instance, we can test whether the <code>zeppo</code> data come from a population with a mean equal to 65:</p>
<div class="sourceCode" id="cb1090"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1090-1"><a href="one-sample-inferential-statistics.html#cb1090-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(zeppo, <span class="at">mu =</span> <span class="dv">65</span>)  <span class="co"># two tailed test</span></span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  zeppo
## t = 3.429, df = 19, p-value = 0.002813
## alternative hypothesis: true mean is not equal to 65
## 95 percent confidence interval:
##  67.84422 76.75578
## sample estimates:
## mean of x 
##      72.3</code></pre>
<p>Again, we see the same t-value, degrees of freedom and p-value as we calculated by hand. Also with a two-tailed t-test we get the 95% confidence interval of the true population mean (see section @ref(calculating -a-t-distribution-confidence-interval).</p>
<p>Finally, if we wished to do a one-tailed t-test where we were testing whether the sample came from a population with a population mean of less than some value, we would use <code>alternative = "less"</code>. For example, to test if the sample of puzzle competitors came from a population that completed their puzzles in less than 16 minutes:</p>
<div class="sourceCode" id="cb1092"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1092-1"><a href="one-sample-inferential-statistics.html#cb1092-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(xt<span class="sc">$</span>time3, <span class="at">mu =</span> <span class="dv">16</span>, <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  xt$time3
## t = -0.98781, df = 9, p-value = 0.1745
## alternative hypothesis: true mean is less than 16
## 95 percent confidence interval:
##      -Inf 16.76313
## sample estimates:
## mean of x 
##  15.10822</code></pre>
<p><br><br></p>
</div>
<div id="assumptions-of-the-one-sample-t-test" class="section level2" number="10.4">
<h2><span class="header-section-number">10.4</span> Assumptions of the one-sample t-test</h2>
<p>The main assumptions of the one-sample t-test are that the observations should be independent of each other, and the values should be approximately normally distributed.</p>
<p>We can more formally test if our data come from a population that is approximately normally distributed using a Shapiro-Wilk test. This test essentially examines the distribution of our data, and determines the probability that it came from a normal distribution. We can perform this test in R using <code>shapiro.test()</code>.</p>
<div class="sourceCode" id="cb1094"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1094-1"><a href="one-sample-inferential-statistics.html#cb1094-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(x)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.98341, p-value = 0.9938</code></pre>
<div class="sourceCode" id="cb1096"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1096-1"><a href="one-sample-inferential-statistics.html#cb1096-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(zeppo)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  zeppo
## W = 0.96205, p-value = 0.5856</code></pre>
<div class="sourceCode" id="cb1098"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1098-1"><a href="one-sample-inferential-statistics.html#cb1098-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(xt<span class="sc">$</span>time3)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  xt$time3
## W = 0.84497, p-value = 0.0506</code></pre>
<div class="sourceCode" id="cb1100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1100-1"><a href="one-sample-inferential-statistics.html#cb1100-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(adelie<span class="sc">$</span>flipper_length_mm)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  adelie$flipper_length_mm
## W = 0.96541, p-value = 0.6056</code></pre>
<p>As you can see, all four of the datasets that we have performed one-sample t-tests on have p-values for this test that are greater than p=0.05. This suggests that our data are approximately normally distributed. The p-value for the crossword puzzle times is very low <code>p=0.0501</code> which probably suggests that we should look at that data in more detail to be sure that our data are normally distributed.</p>
<p>If your data are not normally distributed, then one option is to perform a non-parametric alternative to the one-sample t-test. This test is called the one-sample Wilcoxon signed rank test. We will not go into the details of the test, but effectively it tests whether your sample is likely to have come from a population with a median of a specified value. It is run like this in R:</p>
<div class="sourceCode" id="cb1102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1102-1"><a href="one-sample-inferential-statistics.html#cb1102-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wilcox.test</span>(xt<span class="sc">$</span>time3, <span class="at">mu =</span> <span class="dv">16</span>, <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank exact test
## 
## data:  xt$time3
## V = 19, p-value = 0.2158
## alternative hypothesis: true location is less than 16</code></pre>
<p>Again, with this test, we are looking for a p-value lower than 0.05 to reject the null hypothesis and accept the alternative that our sample comes from a population with a median of less than 16.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hypothesis-testing.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="two-sample-inferential-statistics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jalapic/introstats/edit/master/09-onesample.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/jalapic/introstats/blob/master/09-onesample.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
